---
title: "Analýza rozptylu"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 10)
```

Analýza rozptylu slouží k porovnání průměrů ve více skupinách. Nabýzelo by se použít několik dvouvýběrových t-testů, ale problém s takovýmto použitím t-testů je, že chyba I. druhu v těchto testech se sčítá. Pokud máme $k$ porovnání, pak pravděpodobnost, že uděláme chybu I. druhu je $FWER = 1-(1-\alpha)^k$. Počet porovnání $k$ můžeme vypočítat z počtu skupin $m$ jako $k = \frac{m(m-1)}{2}$. Pojďme si ukázat příklad se 4 skupinami a $\alpha=0.05$.

```{r}
m <- 4
k <- m*(m-1) / 2
alpha <- 0.05
fwer = 1-(1-alpha)^k
print(paste0("Pravděpodobnost chyby I. druhu při ", k, " počtu t-testů je: ", fwer))
```

Řešením je tedy použít analýzu rozptylu (ANOVA). Nulová hypotéza (při 3 skupinách) tohoto testu je $H0: \mu_1=\mu_2=\mu_3$, alternativní hypotéza je $H1: \mu_i \ne \mu_j (pro\;nektere\;skupiny\;i\;a\;j)$, tedy že alespoň jeden průměr je odlišný. 

Testovací statistiku $F$ vypočítáme jako $F=\frac{\frac{\sum_j^mn_j(\bar{x_j}-\bar{x})^2}{m-1}}{\frac{\sum_j^m\sum_i^n(x_{ij} - \bar{x_j})^2}{n-m}}$. Na tento výpočet se můžeme podívat také jako na podíl rozptylu uvnitř skupin / rozptylu mezi skupinami. Zároveň platí, že $\sum_j^m\sum_i^n(x_{ij} - \bar{x})^2=\sum_j^m\sum_i^n(x_{ij} - \bar{x_j})^2 + \sum_j^mn_j(\bar{x_j}-\bar{x})^2$, tedy, že celkovou sumu čtverců můžeme rozložit na sumu čtverců uvnitř skupin a na sumu čtverců mezi skupinami. Testovací statistika $F$ nabývá F rozdělení, které má 2 parametry $sv_1 = m-1$ a $sv_2=n-m$.
Pojďme si tento výpočet ukázat na simulovaných datech. Nejdříve si vytvoříme data, která budou pocházet ze 3 skupin s průměry $mu_1=1, mu_2=1, mu_3=1.5$. Budeme mít 40 pozorování v každé skupině. 
```{r}
set.seed(42) #aby nam vyse
mu <- c(1,1,1.5)
n <- 120 #pocet pozorování
m <- 3 # pocet skupin

# vyber
z <- rnorm(n = n, mean = mu) # nas vyber z populace
k <- rep(c(1,2,3), n/m) # vektor, ktery urcujez jake skupiny je pozorovani
```

Pojďme se podívat na průměr skupin v našem výběru.
```{r}
aggregate(z~k, FUN = mean)
```

Na zobrazení rozložení v jednotlivých skupinách použijeme boxplot. Tento graf zobrazuje, co znamenají jednotlivé hranice boxplotu.
![](https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Boxplot_vs_PDF.svg/1920px-Boxplot_vs_PDF.svg.png)
```{r}
boxplot(z~k, 
        xlab = "Skupina (nezávislá proměnná)", 
        ylab = "Závislá proměnná", 
        main = "Rozložení závislé proměnné ve skupinách")
```

Pro ilustraci si překryjeme boxplot jednotlivými hodnotami.   
```{r}
boxplot(z~k, 
        xlab = "Skupina (nezávislá proměnná)", 
        ylab = "Závislá proměnná", 
        main = "Rozložení závislé proměnné ve skupinách")
points(jitter(k),z, pch = 19, col = adjustcolor("deepskyblue4", alpha.f = 0.5))
```

V naší simulaci samozřejmě známe populační parametry, ale ve většině případů známe pouze výběrové hodnoty a podle nich se snažíme usoudit něco o populaci. Pojďme se tedy podívat, jaké hypotézy bychom pro tento test stanovili. $H_0$ je, že všechny 3 průměry jsou v populaci stejné a $H_1$, že alespoň jeden průměr se liší. Přistupme k výpočtu testovací staitistiky.

```{r}
sum_squares <- function(x, prumer) {
  sum((x-prumer)^2)
}

ss_total <- sum_squares(z, mean(z))
ss_uvnitr <- 0
ss_mezi <- 0
for(i in 1:m) {
  ss_uvnitr <- sum_squares(z[k==i], mean(z[k==i])) + ss_uvnitr
  ss_mezi <- sum(k==i) * sum_squares(mean(z[k==i]), mean(z)) + ss_mezi
}

s_v_1 <- m - 1
s_v_2 <- n - m


f <- (ss_mezi / s_v_1) / (ss_uvnitr / s_v_2)


print(paste0("Celkový sum of squares: ", ss_total))
print(paste0("Sum of squares uvnitř skupin: ", sum(ss_uvnitr)))
print(paste0("Sum of squares mezi skupinami: ", sum(ss_mezi)))
```

Přistupme k interpretaci. Vypočítejme kritickou mez pro $\alpha=0.05$ a vypočítejme hodnotu $p$. Jak vidíme, testovací statistika je v oblasti, kde zamítáme nulovou hypotézu. Tomu odpovídá také hodnota $p$, která je menší než stanovená hladina $\alpha$. 
```{r}
alpha <- 0.05
kriticka_mez <- qf(1-alpha, df1 = s_v_1, df2 = s_v_2) 
p <- 1-pf(f, df1 = s_v_1, df2 = s_v_2)

x <- seq(0, 5, by = 0.001)
pdf <- df(x, df1=s_v_1, df2=s_v_2)
plot(x, pdf, 
     xlab = "Výběrová relativní četnost", ylab = "f(x)", 
     main = "Rozložení rozdílu za předpokladu H0",
     sub = paste0("p-hodnota: ", round(p, 3), " při alpha=", alpha),
     type = "l")
abline(v = kriticka_mez, col = "red")
# oblast zamitnuti H0
for(i in c(1:length(x))) {
  if(x[i] > kriticka_mez) {
    lines(c(x[i], x[i]), c(-1, pdf[i]), 
          col = adjustcolor("red", alpha.f = 0.01))
  }
}
abline(v = f, lty = 2)
legend("topleft", 
       c("kritická mez", "testovací statistika"), 
       col = c("red", "black"), 
       lty = c(1,2))
```

V R bychom pro tento výpočet mohli využít funkci `aov`. 
```{r}
m_anova <- aov(z~as.factor(k)) # pozor nezavisla promenna musi byt factor
s_anova <- summary(m_anova) # takto získáme nejzakladnejsi vysledky
print(s_anova)

# takto bychom mohli reprodukovat graf nahore - pouzijeme vystup z aov a pomoci funkce anova muzeme extrahovat jednotlive hodnoty z anova
anova_vystup <- anova(m_anova)

s_v_1 <- anova_vystup$Df[1]
s_v_2 <- anova_vystup$Df[2]
f <- anova_vystup$`F value`[1]
p <- anova_vystup$`Pr(>F)`[1]

x <- seq(0, 5, by = 0.001)
kriticka_mez <- qf(1-alpha, df1 = s_v_1, df2 = s_v_2) 

pdf <- df(x, df1=s_v_1, df2=s_v_2)
plot(x, pdf, 
     xlab = "Výběrová relativní četnost", ylab = "f(x)", 
     main = "Rozložení rozdílu za předpokladu H0",
     sub = paste0("p-hodnota: ", round(p, 3), " při alpha=", alpha),
     type = "l")
abline(v = kriticka_mez, col = "red")
# oblast zamitnuti H0
for(i in c(1:length(x))) {
  if(x[i] > kriticka_mez) {
    lines(c(x[i], x[i]), c(-1, pdf[i]), 
          col = adjustcolor("red", alpha.f = 0.01))
  }
}
abline(v = f, lty = 2)
legend("topleft", 
       c("kritická mez", "testovací statistika"), 
       col = c("red", "black"), 
       lty = c(1,2))
```